# Spec: Migrate from pgx to Bun ORM with bun/migrate

**Date**: 2026-01-07
**Status**: Draft
**Author**: Claude

## Summary

This specification outlines the migration of PgLens from direct `jackc/pgx/v5` usage to `uptrace/bun` ORM with its built-in migration system (`bun/migrate`). This change will provide:

1. A proper migration framework with version tracking and rollback support
2. Type-safe query building with reduced boilerplate
3. Automatic model-to-table mapping
4. Better maintainability for future schema changes

## Current State

### Database Access Layer
- **Library**: `jackc/pgx/v5` (raw SQL with manual scanning)
- **Connection**: `pgxpool.Pool` for connection pooling
- **Query Pattern**: Hand-written SQL with positional parameters (`$1`, `$2`, etc.)
- **Scanning**: Manual field-by-field scanning into structs

### Migration System
- **Approach**: Single `schema.sql` file embedded via `//go:embed`
- **Execution**: All-or-nothing on first startup (checks if `users` table exists)
- **Version Tracking**: None
- **Rollback Support**: None
- **Limitations**:
  - Cannot apply incremental schema changes
  - No way to rollback failed migrations
  - No audit trail of applied migrations
  - Cannot handle schema evolution in production

### Current Schema (7 tables)
| Table | Purpose |
|-------|---------|
| `users` | PgLens user accounts |
| `databases` | Target database configurations |
| `connections` | Connection history |
| `queries` | Query execution log |
| `query_result_rows` | Stored query results |
| `access_grants` | User-to-database access grants |
| `audit_log` | Audit trail for changes |

### Current Store Files
```
internal/store/
├── store.go          # Pool creation, migration runner
├── schema.sql        # Embedded schema
├── errors.go         # Custom error types
├── users.go          # User CRUD (~200 lines)
├── databases.go      # Database config CRUD (~200 lines)
├── grants.go         # Grant CRUD (~250 lines)
├── connections.go    # Connection logging (~150 lines)
├── queries.go        # Query logging (~200 lines)
├── audit.go          # Audit log (~100 lines)
└── *_test.go         # Test files using testcontainers
```

## Target State

### Database Access Layer
- **Library**: `uptrace/bun` (SQL-first ORM)
- **Connection**: `bun.DB` wrapping `sql.DB` with pgx driver
- **Query Pattern**: Type-safe query builder with optional raw SQL
- **Scanning**: Automatic struct scanning via model tags

### Migration System
- **Library**: `bun/migrate`
- **Approach**: Versioned SQL migrations in `migrations/` directory
- **Execution**: Track applied migrations in `bun_migrations` table
- **Version Tracking**: Automatic via migration names (timestamp-based)
- **Rollback Support**: Full up/down migration support
- **CLI Commands**: `init`, `migrate`, `rollback`, `status`, `create_sql`, `create_go`

## Design Decisions

### 1. Migration Strategy: SQL-based vs Go-based

**Decision**: Use **SQL-based migrations** for schema changes, **Go-based migrations** for data migrations.

**Rationale**:
- SQL migrations are more readable and reviewable
- Schema changes are inherently SQL operations
- Go migrations useful for complex data transformations
- SQL migrations can be reviewed by DBAs without Go knowledge

### 2. Model Definition Strategy

**Decision**: Define bun models with struct tags, keeping models close to current struct definitions.

**Example transformation**:

```go
// Current (users.go)
type User struct {
    ID           int64     `json:"id"`
    Username     string    `json:"username"`
    PasswordHash string    `json:"-"`
    IsAdmin      bool      `json:"is_admin"`
    CreatedAt    time.Time `json:"created_at"`
    UpdatedAt    time.Time `json:"updated_at"`
}

// With Bun
type User struct {
    bun.BaseModel `bun:"table:users,alias:u"`

    ID           int64     `bun:"id,pk,autoincrement" json:"id"`
    Username     string    `bun:"username,notnull,unique" json:"username"`
    PasswordHash string    `bun:"password_hash,notnull" json:"-"`
    IsAdmin      bool      `bun:"is_admin,notnull,default:false" json:"is_admin"`
    CreatedAt    time.Time `bun:"created_at,notnull,default:current_timestamp" json:"created_at"`
    UpdatedAt    time.Time `bun:"updated_at,notnull,default:current_timestamp" json:"updated_at"`
}
```

### 3. Query Migration Strategy

**Decision**: Migrate to bun query builder incrementally, preserving raw SQL for complex queries.

**Example transformations**:

```go
// Current: Manual scanning
func (s *Store) GetUserByID(ctx context.Context, id int64) (*User, error) {
    user := &User{}
    err := s.pool.QueryRow(ctx, `
        SELECT id, username, password_hash, is_admin, created_at, updated_at
        FROM users WHERE id = $1
    `, id).Scan(&user.ID, &user.Username, ...)
    // ... error handling
}

// With Bun: Automatic scanning
func (s *Store) GetUserByID(ctx context.Context, id int64) (*User, error) {
    user := new(User)
    err := s.db.NewSelect().
        Model(user).
        Where("id = ?", id).
        Scan(ctx)
    if err != nil {
        if err == sql.ErrNoRows {
            return nil, ErrUserNotFound
        }
        return nil, fmt.Errorf("failed to get user: %w", err)
    }
    return user, nil
}
```

```go
// Current: Dynamic query building
func (s *Store) ListGrants(ctx context.Context, filter GrantFilter) ([]Grant, error) {
    query := `SELECT ... FROM access_grants WHERE 1=1`
    args := []interface{}{}
    argCount := 1
    if filter.UserID != nil {
        query += fmt.Sprintf(` AND user_id = $%d`, argCount)
        args = append(args, *filter.UserID)
        argCount++
    }
    // ... more conditions
}

// With Bun: Type-safe query builder
func (s *Store) ListGrants(ctx context.Context, filter GrantFilter) ([]Grant, error) {
    var grants []Grant
    q := s.db.NewSelect().Model(&grants)

    if filter.UserID != nil {
        q = q.Where("user_id = ?", *filter.UserID)
    }
    if filter.DatabaseID != nil {
        q = q.Where("database_id = ?", *filter.DatabaseID)
    }
    if filter.ActiveOnly {
        q = q.Where("revoked_at IS NULL").
            Where("starts_at <= NOW()").
            Where("expires_at > NOW()")
    }

    err := q.Order("created_at DESC").Scan(ctx)
    return grants, err
}
```

### 4. Connection Pool Configuration

**Decision**: Use pgx as the underlying driver for bun (via `pgdriver`).

```go
import (
    "github.com/uptrace/bun"
    "github.com/uptrace/bun/dialect/pgdialect"
    "github.com/uptrace/bun/driver/pgdriver"
)

func New(ctx context.Context, dsn string) (*Store, error) {
    sqldb := sql.OpenDB(pgdriver.NewConnector(pgdriver.WithDSN(dsn)))
    db := bun.NewDB(sqldb, pgdialect.New())

    // Connection pool settings
    sqldb.SetMaxOpenConns(25)
    sqldb.SetMaxIdleConns(25)
    sqldb.SetConnMaxLifetime(5 * time.Minute)

    return &Store{db: db}, nil
}
```

### 5. Initial Migration Handling

**Decision**: Create an initial migration that:
1. Handles fresh installs (creates all tables)
2. Handles existing installs (marks migration as applied without running)

The initial migration will be named `20260107000000_initial_schema.up.sql` and contain the current schema.

For existing databases, we'll add a bootstrap check:
```go
func (s *Store) runMigrations(ctx context.Context) error {
    migrator := migrate.NewMigrator(s.db, migrations)

    // Initialize bun_migrations table
    if err := migrator.Init(ctx); err != nil {
        return err
    }

    // Check if this is an existing database (users table exists but no bun_migrations entries)
    var hasUsers bool
    err := s.db.NewSelect().
        TableExpr("information_schema.tables").
        Where("table_name = 'users'").
        Exists(ctx)

    if hasUsers {
        // Existing database - mark initial migration as applied
        _, err = migrator.Migrate(ctx, migrate.WithNop())
        // Or manually insert into bun_migrations
    }

    // Run pending migrations
    _, err = migrator.Migrate(ctx)
    return err
}
```

## Project Structure Changes

### New Directory Structure
```
pglens/
├── cmd/
│   ├── pglens/
│   │   └── main.go           # Main application
│   └── migrate/
│       └── main.go           # Migration CLI tool (optional standalone)
├── internal/
│   ├── store/
│   │   ├── store.go          # Bun DB setup, migration runner
│   │   ├── models.go         # All bun models (NEW)
│   │   ├── users.go          # User operations (simplified)
│   │   ├── databases.go      # Database operations (simplified)
│   │   ├── grants.go         # Grant operations (simplified)
│   │   ├── connections.go    # Connection operations (simplified)
│   │   ├── queries.go        # Query operations (simplified)
│   │   ├── audit.go          # Audit operations (simplified)
│   │   └── errors.go         # Error types (unchanged)
│   └── migrations/
│       ├── migrations.go     # Migration collection registration
│       └── sql/
│           ├── 20260107000000_initial_schema.up.sql
│           ├── 20260107000000_initial_schema.down.sql
│           └── (future migrations)
└── ...
```

### Migration CLI Integration

Add migration subcommands to the main CLI:

```go
// cmd/pglens/main.go
func main() {
    app := &cli.App{
        Commands: []*cli.Command{
            {
                Name:  "serve",
                Usage: "Start PgLens server",
                Action: runServer,
            },
            {
                Name:  "db",
                Usage: "Database migration commands",
                Subcommands: []*cli.Command{
                    {Name: "init", Usage: "Create migration tables", Action: dbInit},
                    {Name: "migrate", Usage: "Run pending migrations", Action: dbMigrate},
                    {Name: "rollback", Usage: "Rollback last migration group", Action: dbRollback},
                    {Name: "status", Usage: "Show migration status", Action: dbStatus},
                    {Name: "create", Usage: "Create new migration", Action: dbCreate},
                },
            },
        },
    }
}
```

## Implementation Plan

### Phase 1: Add Bun Dependency and Models

1. Add bun dependencies to `go.mod`:
   ```
   github.com/uptrace/bun v1.x.x
   github.com/uptrace/bun/dialect/pgdialect v1.x.x
   github.com/uptrace/bun/driver/pgdriver v1.x.x
   github.com/uptrace/bun/migrate v1.x.x
   ```

2. Create `internal/store/models.go` with all bun models:
   - `User`
   - `Database`
   - `Connection`
   - `Query`
   - `QueryResultRow`
   - `AccessGrant`
   - `AuditLog`

3. Create `internal/migrations/` directory structure

### Phase 2: Create Initial Migration

1. Create `internal/migrations/migrations.go`:
   ```go
   package migrations

   import (
       "embed"
       "github.com/uptrace/bun/migrate"
   )

   //go:embed sql/*.sql
   var sqlMigrations embed.FS

   var Migrations = migrate.NewMigrations()

   func init() {
       if err := Migrations.Discover(sqlMigrations); err != nil {
           panic(err)
       }
   }
   ```

2. Create initial migration SQL files from current `schema.sql`

3. Create down migration (DROP tables in reverse order)

### Phase 3: Update Store Layer

1. Update `internal/store/store.go`:
   - Replace `pgxpool.Pool` with `bun.DB`
   - Update `New()` function to create bun.DB
   - Update `runMigrations()` to use bun/migrate
   - Handle existing database bootstrap

2. Update each store file (`users.go`, `databases.go`, etc.):
   - Replace raw SQL with bun query builder
   - Update error handling for `sql.ErrNoRows`
   - Simplify complex query building

### Phase 4: Update Tests

1. Update `internal/store/store_test.go`:
   - Update `setupTestStore()` to return bun.DB-based store
   - Keep testcontainers setup unchanged

2. Update individual test files:
   - Tests should continue to work with minimal changes
   - Verify all existing test cases pass

### Phase 5: Add CLI Migration Commands

1. Add urfave/cli migration subcommands
2. Implement `db init`, `db migrate`, `db rollback`, `db status`, `db create`
3. Update documentation

### Phase 6: Cleanup

1. Remove old `schema.sql` from embed
2. Update `CLAUDE.md` documentation
3. Update docker-compose if needed
4. Final testing and validation

## Risk Assessment

### Low Risk
- Query builder migration (bun supports raw SQL fallback)
- Test migration (same database, same assertions)
- Model definitions (straightforward struct tag additions)

### Medium Risk
- Existing database bootstrap (need careful handling)
- Connection pool behavior differences
- Error type changes (`pgx.ErrNoRows` vs `sql.ErrNoRows`)

### High Risk
- **Production migration**: Existing production databases need the bootstrap logic to recognize already-applied schema

### Mitigation Strategies

1. **Feature flag**: Add `PGL_USE_BUN=true` env var for gradual rollout
2. **Dual-run testing**: Run both pgx and bun implementations in parallel during testing
3. **Backup procedures**: Document database backup before migration
4. **Rollback plan**: Keep pgx code in a branch for quick rollback

## Testing Strategy

### Unit Tests
- All existing store tests must pass unchanged
- Add tests for migration commands

### Integration Tests
- Fresh database: verify migrations create correct schema
- Existing database: verify bootstrap detects and skips initial migration
- Rollback: verify down migrations work correctly

### E2E Tests
- Full application startup with new migration system
- Verify all API endpoints still work
- Verify proxy functionality unchanged

## Dependencies

### New Dependencies
```go
require (
    github.com/uptrace/bun v1.2.x
    github.com/uptrace/bun/dialect/pgdialect v1.2.x
    github.com/uptrace/bun/driver/pgdriver v1.2.x
    github.com/uptrace/bun/migrate v1.2.x
)
```

### Removed Dependencies
- None (pgx is still used under the hood via pgdriver)

### Updated Usage
- `jackc/pgx/v5` - still required as underlying driver

## Documentation Updates

1. Update `CLAUDE.md`:
   - Change "Libraries" section to include bun
   - Add migration CLI commands documentation
   - Update development workflow

2. Add `docs/migrations.md`:
   - How to create new migrations
   - How to run migrations
   - How to rollback
   - Best practices

## Success Criteria

1. All existing tests pass
2. Migration system correctly handles:
   - Fresh database installation
   - Existing database upgrade
   - Migration rollback
3. No functionality regression in API or proxy
4. Migration CLI commands work correctly
5. Code is cleaner with less boilerplate

## Open Questions

1. **Should we use AutoMigrator?** - No, explicit migrations are safer for production
2. **Should we keep raw SQL for complex queries?** - Yes, for the JOIN queries in grants and queries tables
3. **Should we add query logging/debugging?** - Yes, via bun hooks for development mode

## References

- [Bun Documentation](https://bun.uptrace.dev/)
- [Bun Migrations Guide](https://bun.uptrace.dev/guide/migrations.html)
- [Bun GitHub Repository](https://github.com/uptrace/bun)
- [Bun Migration Example](https://github.com/uptrace/bun/tree/master/example/migrate)
- [bun/migrate Package](https://pkg.go.dev/github.com/uptrace/bun/migrate)
